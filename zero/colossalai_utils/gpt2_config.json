{
    "method": "colossalai",
    "model": {
        "type": "gpt2_10b"
    },
    "hyperparameter": {
        "batch_size": 48,
        "steps_per_epoch": 10
    },
    "fp16": {
        "initial_scale": 32768,
        "min_scale": 1,
        "growth_factor": 2.0,
        "backoff_factor": 0.5,
        "growth_interval": 1000
    },
    "gradient_clipping": 0.0,
    "zero": {
        "reduce_scatter_bucket_size_mb": 25,
        "fp32_reduce_scatter": false,
        "offload_config": {
            "device": "cpu"
        },
        "shard_param": true,
        "version": 2
    },
    "use_mem_monitor": true
}